#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‰ªæ˜ ç‰¹æ•ˆæœç´¢å·¥å…·
æ”¯æŒè¾“å…¥å…³é”®è¯æœç´¢å‰ªæ˜ ç‰¹æ•ˆï¼Œå¹¶å°†ç»“æœä¿å­˜ä¸ºJSONæ–‡ä»¶
"""

import requests
import json
import os
import sys
import re
from datetime import datetime
from typing import Dict, List, Optional, Any, Union
from concurrent.futures import ThreadPoolExecutor, as_completed


# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    "keywords": [],  # é»˜è®¤æœç´¢å…³é”®è¯åˆ—è¡¨
    "effect_type": 5,                   # ç‰¹æ•ˆç±»å‹
    "count": 50,                        # æ¯ä¸ªå…³é”®è¯è¿”å›çš„ç»“æœæ•°é‡
    "save_full_result": True,           # æ˜¯å¦ä¿å­˜å®Œæ•´ç»“æœ
    "save_video_urls": True,            # æ˜¯å¦ä¿å­˜è§†é¢‘URL
    "download_videos": False,           # æ˜¯å¦ä¸‹è½½è§†é¢‘
    "max_workers": 5,                   # æœ€å¤§å¹¶å‘ä¸‹è½½æ•°
    "save_dir": "data/results/jianying", # ç»“æœä¿å­˜ç›®å½•
    "video_dir": "data/video",          # è§†é¢‘ä¿å­˜ç›®å½•
    "min_resolution": "1080p",          # æœ€ä½è§†é¢‘åˆ†è¾¨ç‡è¦æ±‚
    "cookies": {                        # é»˜è®¤cookiesé…ç½®
            "store-region": "cn-hb",
            "store-region-src": "uid",
            "n_mh": "8KAIYd9nMFxwSVPpy4XEJKhGL0nyfw_35Nxkilxelck",
            "passport_csrf_token": "311c279e13e613ecc67ce486d0ba89fc",
            "passport_csrf_token_default": "311c279e13e613ecc67ce486d0ba89fc",
            "sid_guard": "fd9ebaee83632608f1ea217f78e4e558%7C1747967643%7C5184000%7CTue%2C+22-Jul-2025+02%3A34%3A03+GMT",
            "uid_tt": "10740e0db45c09735197a4ace7e23f20",
            "uid_tt_ss": "10740e0db45c09735197a4ace7e23f20",
            "sid_tt": "fd9ebaee83632608f1ea217f78e4e558",
            "sessionid": "fd9ebaee83632608f1ea217f78e4e558",
            "sessionid_ss": "fd9ebaee83632608f1ea217f78e4e558",
            "is_staff_user": "false",
            "sid_ucp_v1": "1.0.0-KDMxMTBlNmMzOTA5NjZlNDkzNzNjN2JjNmRiMTM2MmEyM2ZmMTgxZmYKHwiD99C91czNBBCbvb_BBhifrR8gDDCQ-NWyBjgIQCYaAmxmIiBmZDllYmFlZTgzNjMyNjA4ZjFlYTIxN2Y3OGU0ZTU1OA",
            "ssid_ucp_v1": "1.0.0-KDMxMTBlNmMzOTA5NjZlNDkzNzNjN2JjNmRiMTM2MmEyM2ZmMTgxZmYKHwiD99C91czNBBCbvb_BBhifrR8gDDCQ-NWyBjgIQCYaAmxmIiBmZDllYmFlZTgzNjMyNjA4ZjFlYTIxN2Y3OGU0ZTU1OA",
            "_uetvid": "27f18f50f8ac11efafd0f56303409b7b",
            "odin_tt": "fbfde72c09ee8e595b07dcb2ee27f68f31e09d7d61b840ff3a7bb4dd065e3689e9537ceca06b0ec148b103f9f9c5e454d1ae7de4f9b7c2aef70b43499d3a54bc",
            "_tea_web_id": "7397668772687349298",
            "s_v_web_id": "verify_mcburg40_nEP4SLZm_jTgg_4ePs_AD3M_38lbBBofbVEm",
            "COOKIE_CONSENT_PROMPT_CONFIG": "{%22status%22:1%2C%22settings%22:{%22firstPartyAnalytics%22:true%2C%22GoogleAnalytics%22:true}%2C%22updatedTime%22:1750849795438}",
        "ttwid": "1|hMs1clJXG22twhi8wRvpoUzyeaPmKoVyCJxSeR6RhvM|1750849800|7057d47a4f646231d5082ba5d30f95e04f0c2d70bcb96a5ee3f4383fdcd00dab"
    },
    "headers": {                        # é»˜è®¤headersé…ç½®
            "accept": "application/json, text/plain, */*",
            "accept-language": "zh-CN,zh;q=0.9",
            "content-type": "application/json",
            "origin": "https://www.jianying.com",
            "priority": "u=1, i",
            "referer": "https://www.jianying.com/ai-creator/storyboard/23608377858?workspaceId=7397267851037687849&spaceId=7373936382663721254&draftId=881FB5BA-F5DF-4C00-B28C-52E87BAFA205",
            "sec-ch-ua": '"Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"macOS"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
        "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36"
    }
}


class JianyingEffectSearcher:
    """å‰ªæ˜ ç‰¹æ•ˆæœç´¢å™¨"""

    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–å‰ªæ˜ ç‰¹æ•ˆæœç´¢å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼Œé»˜è®¤ä¸ºNoneï¼Œä½¿ç”¨DEFAULT_CONFIG
        """
        # ä½¿ç”¨æä¾›çš„é…ç½®æˆ–é»˜è®¤é…ç½®
        self.config = config if config is not None else DEFAULT_CONFIG
        
        # è®¾ç½®ä¿å­˜ç›®å½•
        self.save_dir = self.config.get("save_dir", "data/results/jianying")
        self.video_dir = self.config.get("video_dir", "data/video")
        self.base_url = "https://www.jianying.com/artist/v1/effect/search"
        
        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        os.makedirs(self.save_dir, exist_ok=True)
        os.makedirs(self.video_dir, exist_ok=True)
        
        # ä»é…ç½®ä¸­è·å–cookieså’Œheaders
        self.cookies = self.config.get("cookies", DEFAULT_CONFIG["cookies"])
        self.headers = self.config.get("headers", DEFAULT_CONFIG["headers"])
        
        # åŸºæœ¬è¯·æ±‚å‚æ•°
        self.params = {
    "aid": "3704",
    "version_name": "18.1.0",
    "version_code": "11.0.0",
    "sdk_version": "18.1.0",
    "effect_sdk_version": "18.1.0",
    "device_platform": "web",
    "language": "zh-Hans",
    "device_type": "web",
    "channel": "online",
}

    def update_cookies(self, new_cookies: Dict[str, str]) -> None:
        """
        æ›´æ–°cookiesé…ç½®
        
        Args:
            new_cookies: æ–°çš„cookieså­—å…¸
        """
        if not new_cookies:
            print("æä¾›çš„cookiesä¸ºç©ºï¼Œä¸è¿›è¡Œæ›´æ–°")
            return
            
        # æ›´æ–°cookies
        self.cookies.update(new_cookies)
        print(f"å·²æ›´æ–° {len(new_cookies)} ä¸ªcookiesé”®å€¼å¯¹")
        
        # åŒæ—¶æ›´æ–°é…ç½®ä¸­çš„cookies
        self.config["cookies"] = self.cookies
        
    def update_headers(self, new_headers: Dict[str, str]) -> None:
        """
        æ›´æ–°headersé…ç½®
        
        Args:
            new_headers: æ–°çš„headerså­—å…¸
        """
        if not new_headers:
            print("æä¾›çš„headersä¸ºç©ºï¼Œä¸è¿›è¡Œæ›´æ–°")
            return
            
        # æ›´æ–°headers
        self.headers.update(new_headers)
        print(f"å·²æ›´æ–° {len(new_headers)} ä¸ªheadersé”®å€¼å¯¹")
        
        # åŒæ—¶æ›´æ–°é…ç½®ä¸­çš„headers
        self.config["headers"] = self.headers
        
    def save_config(self, config_file: str = "config.json") -> bool:
        """
        ä¿å­˜å½“å‰é…ç½®åˆ°æ–‡ä»¶
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºconfig.json
            
        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, ensure_ascii=False, indent=2)
            print(f"é…ç½®å·²ä¿å­˜åˆ° {config_file}")
            return True
        except Exception as e:
            print(f"ä¿å­˜é…ç½®æ–‡ä»¶å¼‚å¸¸: {e}")
            return False

    def search_single_page(self, 
               keyword: str, 
               effect_type: int = 5, 
               count: int = 50, 
               offset: int = 0, 
               need_recommend: bool = True) -> Dict[str, Any]:
        """
        æœç´¢å‰ªæ˜ ç‰¹æ•ˆï¼ˆå•é¡µï¼‰
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            effect_type: ç‰¹æ•ˆç±»å‹ï¼Œé»˜è®¤ä¸º5
            count: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ä¸º50
            offset: åˆ†é¡µåç§»é‡ï¼Œé»˜è®¤ä¸º0
            need_recommend: æ˜¯å¦éœ€è¦æ¨èï¼Œé»˜è®¤ä¸ºTrue
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        
        Raises:
            requests.RequestException: è¯·æ±‚å¼‚å¸¸
            ValueError: å‚æ•°é”™è¯¯
            Exception: å…¶ä»–å¼‚å¸¸
        """
        if not keyword:
            raise ValueError("æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        
        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            json_data = {
                "effect_type": effect_type,
                "query": keyword,
                "from": "normal_search",
                "need_recommend": need_recommend,
                "search_option": {
                    "cc_web_use_new_search": True
                },
                "pack_optional": {
                    "need_thumb": True,
                    "thumb_opt": '{"is_support_webp":1}'
                },
                "count": count,
                "offset": offset
            }

            # å‘é€è¯·æ±‚
            response = requests.post(
                self.base_url,
                params=self.params,
                cookies=self.cookies,
                headers=self.headers,
                json=json_data,
                timeout=30
            )
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            response.raise_for_status()
            
            # è§£æå“åº”æ•°æ®
            result = response.json()
            return result
            
        except requests.RequestException as e:
            print(f"è¯·æ±‚å¼‚å¸¸: {e}")
            raise
        except ValueError as e:
            print(f"å‚æ•°é”™è¯¯: {e}")
            raise
        except Exception as e:
            print(f"æœç´¢ç‰¹æ•ˆæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            raise
            
    def search(self, 
               keyword: str, 
               effect_type: int = 5, 
               count: int = 50, 
               need_recommend: bool = True) -> Dict[str, Any]:
        """
        æœç´¢å‰ªæ˜ ç‰¹æ•ˆï¼ˆåˆ†é¡µè·å–å…¨éƒ¨æ•°æ®ï¼‰
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            effect_type: ç‰¹æ•ˆç±»å‹ï¼Œé»˜è®¤ä¸º5
            count: æ¯é¡µè¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ä¸º50
            need_recommend: æ˜¯å¦éœ€è¦æ¨èï¼Œé»˜è®¤ä¸ºTrue
            
        Returns:
            åˆå¹¶åçš„æœç´¢ç»“æœå­—å…¸
        
        Raises:
            requests.RequestException: è¯·æ±‚å¼‚å¸¸
            ValueError: å‚æ•°é”™è¯¯
            Exception: å…¶ä»–å¼‚å¸¸
        """
        import time
        import random
        
        if not keyword:
            raise ValueError("æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        
        # åˆå§‹åŒ–ç»“æœï¼Œç”¨äºåˆå¹¶æ‰€æœ‰é¡µé¢çš„æ•°æ®
        merged_result = None
        offset = 0
        has_more = True
        page_num = 1
        
        try:
            while has_more:
                print(f"è·å–ç¬¬ {page_num} é¡µæ•°æ®ï¼Œå…³é”®è¯: {keyword}, offset: {offset}")
                
                # è·å–å½“å‰é¡µæ•°æ®
                current_page = self.search_single_page(
                    keyword=keyword,
                    effect_type=effect_type,
                    count=count,
                    offset=offset,
                    need_recommend=need_recommend
                )
                
                # ç¬¬ä¸€é¡µæ—¶åˆå§‹åŒ–åˆå¹¶ç»“æœ
                if merged_result is None:
                    merged_result = current_page.copy()
                    if 'data' not in merged_result or 'effect_item_list' not in merged_result['data']:
                        print(f"æœç´¢ç»“æœæ•°æ®æ ¼å¼å¼‚å¸¸")
                        break
                # å¦åˆ™åˆå¹¶effect_item_list
                elif 'data' in current_page and 'effect_item_list' in current_page['data']:
                    merged_result['data']['effect_item_list'].extend(current_page['data']['effect_item_list'])
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šæ•°æ®
                has_more = current_page.get('data', {}).get('has_more', False)
                next_offset = current_page.get('data', {}).get('next_offset', 0)
                
                if has_more and next_offset > offset:
                    offset = next_offset
                    page_num += 1
                    
                    # æ·»åŠ éšæœºå»¶è¿Ÿï¼ˆ1-2ç§’ï¼‰
                    delay = 1.0 + random.random()
                    print(f"ç­‰å¾… {delay:.2f} ç§’åè·å–ä¸‹ä¸€é¡µ...")
                    time.sleep(delay)
                else:
                    # æ²¡æœ‰æ›´å¤šæ•°æ®æˆ–offsetæ²¡æœ‰å˜åŒ–ï¼Œç»“æŸå¾ªç¯
                    has_more = False
                    
            print(f"å…±è·å– {page_num} é¡µæ•°æ®ï¼Œå…³é”®è¯: {keyword}")
            
            # æ›´æ–°åˆå¹¶åçš„è®¡æ•°ä¿¡æ¯
            if merged_result and 'data' in merged_result:
                total_items = len(merged_result['data'].get('effect_item_list', []))
                print(f"å…±è·å– {total_items} æ¡æ•°æ®")
                
                # æ›´æ–°æ•°æ®ç»Ÿè®¡ä¿¡æ¯
                merged_result['data']['total'] = total_items
                merged_result['data']['has_more'] = False
                merged_result['data']['next_offset'] = 0
            
            return merged_result
            
        except Exception as e:
            print(f"åˆ†é¡µæœç´¢ç‰¹æ•ˆæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            # å¦‚æœå·²ç»è·å–äº†éƒ¨åˆ†æ•°æ®ï¼Œè¿”å›å·²è·å–çš„æ•°æ®
            if merged_result:
                print(f"è¿”å›å·²è·å–çš„ {page_num-1} é¡µæ•°æ®")
                return merged_result
            raise

    def save_result(self, result: Dict[str, Any], keyword: str, file_name: Optional[str] = None) -> str:
        """
        ä¿å­˜æœç´¢ç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            result: æœç´¢ç»“æœ
            keyword: æœç´¢å…³é”®è¯
            file_name: æ–‡ä»¶åï¼Œé»˜è®¤ä¸ºNoneï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
            
        Raises:
            IOError: æ–‡ä»¶æ“ä½œå¼‚å¸¸
            Exception: å…¶ä»–å¼‚å¸¸
        """
        try:
            # å¦‚æœæ²¡æœ‰æä¾›æ–‡ä»¶åï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆ
            if not file_name:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_name = f"jianying_effect_{keyword}_{timestamp}.json"
            
            # ç¡®ä¿æ–‡ä»¶åæœ‰.jsonåç¼€
            if not file_name.endswith('.json'):
                file_name += '.json'
            
            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(self.save_dir, file_name)
            
            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"æœç´¢ç»“æœå·²ä¿å­˜åˆ°: {file_path}")
            return file_path
        
        except IOError as e:
            print(f"ä¿å­˜æ–‡ä»¶å¼‚å¸¸: {e}")
            raise
        except Exception as e:
            print(f"ä¿å­˜ç»“æœæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            raise
    
    def extract_video_urls(self, result: Dict[str, Any], keyword: str, file_name: Optional[str] = None) -> str:
        """
        ä»æœç´¢ç»“æœä¸­æå–origin_videoçš„video_urlå¹¶ä¿å­˜åˆ°å•ç‹¬çš„JSONæ–‡ä»¶
        
        Args:
            result: æœç´¢ç»“æœ
            keyword: æœç´¢å…³é”®è¯
            file_name: æ–‡ä»¶åï¼Œé»˜è®¤ä¸ºNoneï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
            
        Raises:
            IOError: æ–‡ä»¶æ“ä½œå¼‚å¸¸
            Exception: å…¶ä»–å¼‚å¸¸
        """
        try:
            # æå–æ‰€æœ‰è§†é¢‘URL
            video_urls = []
            
            if 'data' in result and 'effect_item_list' in result['data']:
                for item in result['data']['effect_item_list']:
                    if 'video' in item and 'origin_video' in item['video']:
                        origin_video = item['video']['origin_video']
                        video_info = {
                            'title': item['common_attr']['title'],
                            'description': item['common_attr']['description'],
                            'video_url': origin_video.get('video_url', ''),
                            'format': origin_video.get('format', ''),
                            'definition': origin_video.get('definition', ''),
                            'height': origin_video.get('height', 0),
                            'width': origin_video.get('width', 0),
                            'size': origin_video.get('size', 0)
                        }
                        video_urls.append(video_info)
            
            # å¦‚æœæ²¡æœ‰æä¾›æ–‡ä»¶åï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆ
            if not file_name:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_name = f"jianying_video_urls_{keyword}_{timestamp}.json"
            
            # ç¡®ä¿æ–‡ä»¶åæœ‰.jsonåç¼€
            if not file_name.endswith('.json'):
                file_name += '.json'
            
            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(self.save_dir, file_name)
            
            # ä¿å­˜è§†é¢‘URLåˆ°JSONæ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(video_urls, f, ensure_ascii=False, indent=2)
            
            print(f"è§†é¢‘URLå·²ä¿å­˜åˆ°: {file_path}")
            return file_path
        
        except IOError as e:
            print(f"ä¿å­˜è§†é¢‘URLå¼‚å¸¸: {e}")
            raise
        except Exception as e:
            print(f"æå–è§†é¢‘URLæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            raise

    def sanitize_filename(self, filename: str) -> str:
        """
        æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸åˆæ³•å­—ç¬¦
        
        Args:
            filename: åŸå§‹æ–‡ä»¶å
            
        Returns:
            æ¸…ç†åçš„æ–‡ä»¶å
        """
        # ç§»é™¤ä¸åˆæ³•å­—ç¬¦
        sanitized = re.sub(r'[\\/*?:"<>|]', '', filename)
        # æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿
        sanitized = sanitized.replace(' ', '_')
        # å¦‚æœæ–‡ä»¶åä¸ºç©ºï¼Œè¿”å›é»˜è®¤åç§°
        if not sanitized:
            return "unnamed_video"
        return sanitized.strip()

    def is_hd_video(self, video_info: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­è§†é¢‘æ˜¯å¦ä¸ºé«˜æ¸…ï¼ˆ1080påŠä»¥ä¸Šï¼‰
        
        Args:
            video_info: è§†é¢‘ä¿¡æ¯
            
        Returns:
            æ˜¯å¦ä¸ºé«˜æ¸…è§†é¢‘
        """
        # ä»é…ç½®ä¸­è·å–æœ€ä½åˆ†è¾¨ç‡è¦æ±‚
        min_resolution = self.config.get("min_resolution", "1080p")
        
        # è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯
        definition = video_info.get('definition', '')
        height = video_info.get('height', 0)
        width = video_info.get('width', 0)
        
        # æ ¹æ®definitionå­—æ®µåˆ¤æ–­
        if definition:
            if min_resolution == "1080p":
                return "1080" in definition or "2K" in definition or "4K" in definition or "HD" in definition.upper()
            elif min_resolution == "720p":
                return "720" in definition or "1080" in definition or "2K" in definition or "4K" in definition or "HD" in definition.upper()
        
        # æ ¹æ®é«˜åº¦åˆ¤æ–­
        if height >= 1080:
            return True
        
        return False
        
    def download_video(self, video_info: Dict[str, Any], keyword: str, index: int) -> str:
        """
        ä¸‹è½½å•ä¸ªè§†é¢‘
        
        Args:
            video_info: è§†é¢‘ä¿¡æ¯
            keyword: æœç´¢å…³é”®è¯
            index: è§†é¢‘ç´¢å¼•
            
        Returns:
            ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„
        
        Raises:
            requests.RequestException: è¯·æ±‚å¼‚å¸¸
            IOError: æ–‡ä»¶æ“ä½œå¼‚å¸¸
            Exception: å…¶ä»–å¼‚å¸¸
        """
        try:
            # æ£€æŸ¥åˆ†è¾¨ç‡
            if not self.is_hd_video(video_info):
                print(f"è§†é¢‘ {index} åˆ†è¾¨ç‡ä½äºè¦æ±‚(1080p)ï¼Œè·³è¿‡ä¸‹è½½")
                return ""
                
            # è·å–è§†é¢‘URL
            video_url = video_info.get('video_url')
            if not video_url:
                print(f"è§†é¢‘ {index} æ²¡æœ‰URLï¼Œè·³è¿‡ä¸‹è½½")
                return ""
            
            # è·å–è§†é¢‘æ ¼å¼
            video_format = video_info.get('format', 'mp4')
            
            # ç¡®å®šæ–‡ä»¶å
            title = video_info.get('title', '').strip()
            if title:
                filename = self.sanitize_filename(title)
            else:
                filename = f"{keyword}_{index}"
            
            # ç¡®ä¿æ–‡ä»¶åæœ‰æ­£ç¡®çš„åç¼€
            if not filename.endswith(f'.{video_format}'):
                filename += f'.{video_format}'
            
            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            # æŒ‰å…³é”®è¯åˆ›å»ºå­ç›®å½•
            keyword_dir = os.path.join(self.video_dir, self.sanitize_filename(keyword))
            os.makedirs(keyword_dir, exist_ok=True)

            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(keyword_dir, filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(file_path):
                print(f"æ–‡ä»¶å·²å­˜åœ¨: {file_path}ï¼Œè·³è¿‡ä¸‹è½½")
                return file_path
            
            # ä¸‹è½½è§†é¢‘
            print(f"æ­£åœ¨ä¸‹è½½è§†é¢‘: {filename}")
            response = requests.get(video_url, stream=True, timeout=60)
            response.raise_for_status()
            
            # ä¿å­˜è§†é¢‘
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            print(f"è§†é¢‘ä¸‹è½½å®Œæˆ: {file_path}")
            return file_path
        
        except requests.RequestException as e:
            print(f"ä¸‹è½½è§†é¢‘å¼‚å¸¸: {e}")
            return ""
        except IOError as e:
            print(f"ä¿å­˜è§†é¢‘å¼‚å¸¸: {e}")
            return ""
        except Exception as e:
            print(f"ä¸‹è½½è§†é¢‘æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return ""

    def download_videos(self, video_urls_file: str, max_workers: int = 5) -> List[str]:
        """
        ä¸‹è½½JSONæ–‡ä»¶ä¸­çš„æ‰€æœ‰è§†é¢‘
        
        Args:
            video_urls_file: è§†é¢‘URLæ–‡ä»¶è·¯å¾„
            max_workers: æœ€å¤§å¹¶å‘ä¸‹è½½æ•°ï¼Œé»˜è®¤ä¸º5
            
        Returns:
            ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        
        Raises:
            IOError: æ–‡ä»¶æ“ä½œå¼‚å¸¸
            Exception: å…¶ä»–å¼‚å¸¸
        """
        try:
            # è¯»å–è§†é¢‘URLæ–‡ä»¶
            with open(video_urls_file, 'r', encoding='utf-8') as f:
                video_urls = json.load(f)
            
            if not video_urls:
                print("æ²¡æœ‰æ‰¾åˆ°è§†é¢‘URLï¼Œè·³è¿‡ä¸‹è½½")
                return []
            
            # æå–å…³é”®è¯
            filename = os.path.basename(video_urls_file)
            match = re.search(r'jianying_video_urls_(.+?)_\d+', filename)
            keyword = match.group(1) if match else "unknown"
            
            # è¿‡æ»¤ç¬¦åˆåˆ†è¾¨ç‡è¦æ±‚çš„è§†é¢‘
            min_resolution = self.config.get("min_resolution", "1080p")
            hd_video_count = sum(1 for video in video_urls if self.is_hd_video(video))
            print(f"æ‰¾åˆ° {hd_video_count}/{len(video_urls)} ä¸ªç¬¦åˆåˆ†è¾¨ç‡è¦æ±‚({min_resolution}+)çš„è§†é¢‘")
            
            downloaded_files = []
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸‹è½½
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
                future_to_index = {
                    executor.submit(self.download_video, video_info, keyword, i): i 
                    for i, video_info in enumerate(video_urls)
                }
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                for future in as_completed(future_to_index):
                    index = future_to_index[future]
                    try:
                        file_path = future.result()
                        if file_path:
                            downloaded_files.append(file_path)
                    except Exception as e:
                        print(f"ä¸‹è½½è§†é¢‘ {index} å¤±è´¥: {e}")
            
            print(f"å…±ä¸‹è½½ {len(downloaded_files)}/{hd_video_count} ä¸ªç¬¦åˆæ¡ä»¶çš„è§†é¢‘")
            return downloaded_files
        
        except IOError as e:
            print(f"è¯»å–è§†é¢‘URLæ–‡ä»¶å¼‚å¸¸: {e}")
            raise
        except Exception as e:
            print(f"ä¸‹è½½è§†é¢‘æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            raise

    def search_and_save(self, 
                        keyword: str, 
                        effect_type: int = None, 
                        count: int = None, 
                        save_full_result: bool = None,
                        save_video_urls: bool = None,
                        download_videos: bool = None,
                        file_name: Optional[str] = None,
                        video_urls_file_name: Optional[str] = None,
                        max_workers: int = None) -> Dict[str, Any]:
        """
        æœç´¢å¹¶ä¿å­˜ç»“æœçš„ä¾¿æ·æ–¹æ³•
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            effect_type: ç‰¹æ•ˆç±»å‹ï¼Œé»˜è®¤ä»é…ç½®ä¸­è·å–
            count: æ¯é¡µè¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ä»é…ç½®ä¸­è·å–
            save_full_result: æ˜¯å¦ä¿å­˜å®Œæ•´ç»“æœï¼Œé»˜è®¤ä»é…ç½®ä¸­è·å–
            save_video_urls: æ˜¯å¦ä¿å­˜è§†é¢‘URLï¼Œé»˜è®¤ä»é…ç½®ä¸­è·å–
            download_videos: æ˜¯å¦ä¸‹è½½è§†é¢‘ï¼Œé»˜è®¤ä»é…ç½®ä¸­è·å–
            file_name: å®Œæ•´ç»“æœæ–‡ä»¶åï¼Œé»˜è®¤ä¸ºNoneï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆ
            video_urls_file_name: è§†é¢‘URLæ–‡ä»¶åï¼Œé»˜è®¤ä¸ºNoneï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆ
            max_workers: æœ€å¤§å¹¶å‘ä¸‹è½½æ•°ï¼Œé»˜è®¤ä»é…ç½®ä¸­è·å–
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å’Œä¸‹è½½çš„è§†é¢‘æ–‡ä»¶è·¯å¾„å­—å…¸
            
        Raises:
            Exception: ä»»ä½•å¼‚å¸¸
        """
        try:
            # ä½¿ç”¨å‚æ•°æˆ–é…ç½®å€¼
            effect_type = effect_type if effect_type is not None else self.config.get("effect_type", 5)
            count = count if count is not None else self.config.get("count", 50)
            save_full_result = save_full_result if save_full_result is not None else self.config.get("save_full_result", True)
            save_video_urls = save_video_urls if save_video_urls is not None else self.config.get("save_video_urls", True)
            download_videos = download_videos if download_videos is not None else self.config.get("download_videos", False)
            max_workers = max_workers if max_workers is not None else self.config.get("max_workers", 5)
            
            print(f"å¼€å§‹æœç´¢å…³é”®è¯ '{keyword}'ï¼Œè‡ªåŠ¨åˆ†é¡µè·å–å…¨éƒ¨ç»“æœ")
            
            # æœç´¢ç‰¹æ•ˆï¼ˆè‡ªåŠ¨åˆ†é¡µè·å–å…¨éƒ¨ç»“æœï¼‰
            result = self.search(keyword, effect_type, count)
            
            # è·å–æ€»æ¡æ•°
            total_items = len(result.get('data', {}).get('effect_item_list', []))
            print(f"å…³é”®è¯ '{keyword}' æœç´¢å®Œæˆï¼Œå…±è·å– {total_items} æ¡æ•°æ®")
            
            saved_paths = {}
            
            # ä¿å­˜å®Œæ•´ç»“æœ
            if save_full_result:
                full_result_path = self.save_result(result, keyword, file_name)
                saved_paths['full_result_path'] = full_result_path
            
            # æå–å¹¶ä¿å­˜è§†é¢‘URL
            if save_video_urls or download_videos:
                video_urls_path = self.extract_video_urls(result, keyword, video_urls_file_name)
                saved_paths['video_urls_path'] = video_urls_path
                
                # ä¸‹è½½è§†é¢‘
                if download_videos:
                    downloaded_files = self.download_videos(video_urls_path, max_workers)
                    saved_paths['downloaded_videos'] = downloaded_files
            
            return saved_paths
        
        except Exception as e:
            print(f"æœç´¢å¹¶ä¿å­˜ç»“æœæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            raise

    def process_multiple_keywords(self) -> Dict[str, Any]:
        """
        å¤„ç†å¤šä¸ªå…³é”®è¯çš„æœç´¢
        
        Returns:
            æ‰€æœ‰å…³é”®è¯çš„å¤„ç†ç»“æœå­—å…¸
        """
        all_results = {}
        keywords = self.config.get("keywords", ["ç»¿èŒ¶"])
        
        for keyword in keywords:
            print(f"\næ­£åœ¨å¤„ç†å…³é”®è¯: {keyword}")
            try:
                result = self.search_and_save(
                    keyword=keyword,
                    effect_type=self.config.get("effect_type"),
                    count=self.config.get("count"),
                    save_full_result=self.config.get("save_full_result"),
                    save_video_urls=self.config.get("save_video_urls"),
                    download_videos=self.config.get("download_videos"),
                    max_workers=self.config.get("max_workers")
                )
                all_results[keyword] = result
            except Exception as e:
                print(f"å¤„ç†å…³é”®è¯ '{keyword}' æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                all_results[keyword] = {"error": str(e)}
        
        return all_results
    
    
    def save_results_only(self) -> Dict[str, str]:
        """
        åªæœç´¢å¹¶ä¿å­˜ç»“æœå’Œè§†é¢‘URLï¼Œä¸ä¸‹è½½è§†é¢‘ã€‚
        
        Returns:
            Dict[str, str]ï¼šå…³é”®è¯å¯¹åº”çš„ video_urls JSON æ–‡ä»¶è·¯å¾„
        """
        all_video_url_paths = {}
        keywords = self.config.get("keywords", ["ç»¿èŒ¶"])

        for keyword in keywords:
           print(f"\nğŸ” æ­£åœ¨å¤„ç†å…³é”®è¯: {keyword}")
           try:
               result = self.search(keyword)
               self.save_result(result, keyword)
               video_urls_path = self.extract_video_urls(result, keyword)
               all_video_url_paths[keyword] = video_urls_path
           except Exception as e:
               print(f"å…³é”®è¯ '{keyword}' å¤„ç†å¼‚å¸¸: {e}")
               all_video_url_paths[keyword] = None
        return all_video_url_paths
        
    def download_all_videos_from_saved_urls(self, url_paths: Dict[str, str]):
        """
        æ‰¹é‡ä»ä¿å­˜çš„è§†é¢‘URL JSONæ–‡ä»¶ä¸­ä¸‹è½½è§†é¢‘ã€‚
    
        Args:
        url_paths: æ¯ä¸ªå…³é”®è¯å¯¹åº”çš„è§†é¢‘URLæ–‡ä»¶è·¯å¾„
        """
        for keyword, path in url_paths.items():
            if path:
                try:
                    print(f"\nâ¬‡ï¸ å¼€å§‹ä¸‹è½½å…³é”®è¯ '{keyword}' çš„è§†é¢‘")
                    self.download_videos(path, self.config.get("max_workers", 5))
                except Exception as e:
                    print(f"å…³é”®è¯ '{keyword}' ä¸‹è½½è§†é¢‘å¼‚å¸¸: {e}")






def load_config(config_file: str = "config.json") -> Dict[str, Any]:
    """
    ä»JSONæ–‡ä»¶åŠ è½½é…ç½®
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºconfig.json
        
    Returns:
        é…ç½®å­—å…¸
    """
    try:
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æ£€æŸ¥å¹¶è®°å½•é…ç½®ä¿¡æ¯
            print(f"å·²ä» {config_file} åŠ è½½é…ç½®")
            
            # æ£€æŸ¥cookiesé…ç½®
            if "cookies" in config:
                print(f"âœ“ å·²åŠ è½½cookiesé…ç½®ï¼ŒåŒ…å« {len(config['cookies'])} ä¸ªé”®å€¼å¯¹")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°cookiesé…ç½®ï¼Œå°†ä½¿ç”¨é»˜è®¤cookies")
                config["cookies"] = DEFAULT_CONFIG["cookies"]
            
            # æ£€æŸ¥headersé…ç½®
            if "headers" in config:
                print(f"âœ“ å·²åŠ è½½headersé…ç½®ï¼ŒåŒ…å« {len(config['headers'])} ä¸ªé”®å€¼å¯¹")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°headersé…ç½®ï¼Œå°†ä½¿ç”¨é»˜è®¤headers")
                config["headers"] = DEFAULT_CONFIG["headers"]
                
            return config
        else:
            print(f"é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return DEFAULT_CONFIG
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶å¼‚å¸¸: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return DEFAULT_CONFIG


# æ›¿æ¢åŸæ¥çš„ main å‡½æ•°
def main():
    """ä¸»å‡½æ•°ï¼šåˆ†é˜¶æ®µæ‰§è¡Œ"""
    try:
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        import argparse
        
        parser = argparse.ArgumentParser(description='å‰ªæ˜ ç‰¹æ•ˆæœç´¢å·¥å…·')
        
        # è‡ªåŠ¨æ£€æµ‹é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œä½¿å…¶åœ¨æ‰“åŒ…åä¹Ÿèƒ½æ­£å¸¸å·¥ä½œ
        if getattr(sys, 'frozen', False):
            # å¦‚æœæ˜¯æ‰“åŒ…åçš„å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè·å–å…¶æ‰€åœ¨ç›®å½•
            application_path = os.path.dirname(sys.executable)
        else:
            # å¦‚æœæ˜¯ä½œä¸ºæ™®é€šè„šæœ¬è¿è¡Œï¼Œè·å–è„šæœ¬æ‰€åœ¨ç›®å½•
            application_path = os.path.dirname(os.path.abspath(__file__))
        
        # é»˜è®¤çš„é…ç½®æ–‡ä»¶è·¯å¾„ä¸ºç¨‹åºæ‰€åœ¨ç›®å½•ä¸‹çš„ config.json
        default_config_path = os.path.join(application_path, 'config.json')
        
        parser.add_argument('-c', '--config', default=default_config_path, help='é…ç½®æ–‡ä»¶è·¯å¾„')
        parser.add_argument('--search-only', action='store_true', help='åªæœç´¢å¹¶ä¿å­˜ç»“æœï¼Œä¸ä¸‹è½½è§†é¢‘')
        parser.add_argument('--download-only', action='store_true', help='åªä»å·²ä¿å­˜çš„URLæ–‡ä»¶ä¸‹è½½è§†é¢‘')
        parser.add_argument('--update-cookies', action='store_true', help='æ›´æ–°cookieså¹¶ä¿å­˜åˆ°é…ç½®æ–‡ä»¶')
        parser.add_argument('--cookies-file', help='ä»JSONæ–‡ä»¶åŠ è½½cookies')
        parser.add_argument('--save-config', action='store_true', help='ä¿å­˜å½“å‰é…ç½®åˆ°æ–‡ä»¶')
        parser.add_argument('--min-resolution', choices=['720p', '1080p', '2K', '4K'], default='1080p', 
                          help='æœ€ä½è§†é¢‘åˆ†è¾¨ç‡è¦æ±‚ (é»˜è®¤: 1080p)')
        
        # æ·»åŠ ä¸€ä¸ªä¸“é—¨çš„å‚æ•°æ¥æ˜¾ç¤ºé…ç½®ç¤ºä¾‹
        parser.add_argument('--show-config-example', action='store_true', help='æ˜¾ç¤ºé…ç½®æ–‡ä»¶æ ¼å¼ç¤ºä¾‹')
        
        args = parser.parse_args()
        
        # æ˜¾ç¤ºé…ç½®ç¤ºä¾‹
        if args.show_config_example:
            print("é…ç½®æ–‡ä»¶æ ¼å¼ç¤ºä¾‹:")
            print(json.dumps(DEFAULT_CONFIG, ensure_ascii=False, indent=2))
            return

        # åŠ è½½é…ç½®
        config = load_config(args.config)
        
        # æ›´æ–°é…ç½®ä¸­çš„åˆ†è¾¨ç‡è®¾ç½®
        if args.min_resolution:
            config["min_resolution"] = args.min_resolution
            
        searcher = JianyingEffectSearcher(config)
        
        # æ›´æ–°cookies
        if args.update_cookies:
            if args.cookies_file:
                try:
                    with open(args.cookies_file, 'r', encoding='utf-8') as f:
                        new_cookies = json.load(f)
                    searcher.update_cookies(new_cookies)
                    if args.save_config:
                        searcher.save_config(args.config)
                except Exception as e:
                    print(f"ä»æ–‡ä»¶åŠ è½½cookieså¼‚å¸¸: {e}")
                    return
            else:
                print("è¯·ä½¿ç”¨ --cookies-file å‚æ•°æŒ‡å®šcookiesæ–‡ä»¶è·¯å¾„")
                return
        
        # ä¿å­˜é…ç½®
        if args.save_config and not args.update_cookies:
            searcher.save_config(args.config)
            return
            
        # åªä¸‹è½½è§†é¢‘
        if args.download_only:
            # æŸ¥æ‰¾æ‰€æœ‰è§†é¢‘URLæ–‡ä»¶
            import glob
            video_url_files = glob.glob(os.path.join(searcher.save_dir, "jianying_video_urls_*.json"))
            
            if not video_url_files:
                print("æœªæ‰¾åˆ°è§†é¢‘URLæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œæœç´¢")
                return
                
            print(f"æ‰¾åˆ° {len(video_url_files)} ä¸ªè§†é¢‘URLæ–‡ä»¶")
            
            # æ„å»ºURLæ–‡ä»¶è·¯å¾„å­—å…¸
            url_paths = {}
            for file_path in video_url_files:
                filename = os.path.basename(file_path)
                match = re.search(r'jianying_video_urls_(.+?)_\d+', filename)
                keyword = match.group(1) if match else "unknown"
                url_paths[keyword] = file_path
                
            # ä¸‹è½½è§†é¢‘
            searcher.download_all_videos_from_saved_urls(url_paths)
            return
        
        # é»˜è®¤è¡Œä¸ºï¼šæœç´¢å¹¶å¯é€‰ä¸‹è½½
        saved_url_paths = searcher.save_results_only()
        
        # å¦‚æœé…ç½®ä¸ºä¸‹è½½è§†é¢‘ä¸”ä¸æ˜¯åªæœç´¢æ¨¡å¼
        if config.get("download_videos", False) and not args.search_only:
            searcher.download_all_videos_from_saved_urls(saved_url_paths)

        # æ‰“å°æ€»ç»“
        print("\nå¤„ç†æ‘˜è¦ï¼š")
        for keyword, path in saved_url_paths.items():
            if path:
                print(f"å…³é”®è¯ '{keyword}'ï¼šå·²ä¿å­˜è§†é¢‘ URL æ–‡ä»¶ -> {path}")
            else:
                print(f"å…³é”®è¯ '{keyword}'ï¼šå¤„ç†å¤±è´¥")

    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)



if __name__ == "__main__":
    main()

